{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "victorian-reading",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The code is extensively uses the ACN implementation, please see:\n",
    "## https://github.com/Wangyixinxin/ACN##\n",
    "#!/usr/bin/env python3\n",
    "# encoding: utf-8\n",
    "import yaml\n",
    "from data import make_data_loaders\n",
    "from models import build_model\n",
    "from models.discriminator import get_style_discriminator\n",
    "from solver import make_optimizer_double\n",
    "from losses import get_losses, bce_loss, DiceLoss\n",
    "import os\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from utils import init_env\n",
    "import nibabel as nib\n",
    "import numpy as np\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "opened-iraqi",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_old_model(model_full, model_missing, d_style, optimizer, saved_model_path):\n",
    "    print(\"Constructing model from saved file... \")\n",
    "    checkpoint = torch.load(saved_model_path)\n",
    "    model_full.load_state_dict(checkpoint[\"model_full\"])\n",
    "    model_missing.load_state_dict(checkpoint[\"model_missing\"])\n",
    "    optimizer.load_state_dict(checkpoint[\"optimizer\"])\n",
    "    d_style.load_state_dict(checkpoint[\"d_style\"])\n",
    "    epoch = checkpoint[\"epochs\"]\n",
    "\n",
    "    return model_full, model_missing, d_style, optimizer, epoch\n",
    "        \n",
    "def to_numpy(tensor):\n",
    "    if isinstance(tensor, (int, float)):\n",
    "        return tensor\n",
    "    else:\n",
    "        return tensor.data.cpu().numpy()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "concerned-surname",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Main section\n",
    "config = yaml.load(open('./config.yml'), Loader=yaml.FullLoader)\n",
    "init_env('0')\n",
    "loaders = make_data_loaders(config)\n",
    "model_full, model_missing = build_model(inp_dim1 = 4, inp_dim2 = 1)\n",
    "model_full    = model_full.cuda()\n",
    "model_missing = model_missing.cuda()\n",
    "d_style       = get_style_discriminator(num_classes = 128).cuda()\n",
    "task_name = 'brats2018_flair'\n",
    "log_dir = os.path.join(config['path_to_log'], task_name)\n",
    "optimizer, scheduler = make_optimizer_double(config, model_full, model_missing)\n",
    "losses = get_losses(config)\n",
    "\n",
    "continue_training = False\n",
    "epoch = 0\n",
    "\n",
    "if not os.path.exists(log_dir):\n",
    "    os.makedirs(log_dir)  \n",
    "    \n",
    "criteria = DiceLoss() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "worth-circular",
   "metadata": {},
   "outputs": [],
   "source": [
    "## evalute the performance\n",
    "def get_mask(seg_volume):\n",
    "    seg_volume = seg_volume.detach().cpu().numpy()\n",
    "    seg_volume = np.squeeze(seg_volume)\n",
    "    wt_pred = seg_volume[0]\n",
    "    tc_pred = seg_volume[1]\n",
    "    et_pred = seg_volume[2]\n",
    "    mask = np.zeros_like(wt_pred)\n",
    "    mask[wt_pred > 0.5] = 2\n",
    "    mask[tc_pred > 0.5] = 1\n",
    "    mask[et_pred > 0.5] = 4\n",
    "    mask = mask.astype(\"uint8\")\n",
    "    return mask\n",
    "\n",
    "def eval_metrics(gt, pred):\n",
    "    loss_wt = criteria(np.where(gt>0, 1, 0), np.where(pred>0, 1, 0))\n",
    "    loss_ct = criteria(np.where(gt==1, 1, 0)+np.where(gt==4, 1, 0), np.where(pred==1, 1, 0)+np.where(pred==4, 1, 0))\n",
    "    loss_et = criteria(np.where(gt==4, 1, 0), np.where(pred==4, 1, 0))\n",
    "    return loss_wt, loss_et, loss_ct\n",
    "\n",
    "def measure_dice_score(batch_pred, batch_y):\n",
    "    pred = get_mask(batch_pred)\n",
    "    gt   = get_mask(batch_y)\n",
    "    loss_wt, loss_et, loss_ct = eval_metrics(gt, pred)\n",
    "    score = (loss_wt+loss_et+loss_ct)/3.0\n",
    "    \n",
    "    return score\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "guided-proxy",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_val(model_full, model_missing, d_style, loaders, optimizer, scheduler, losses, epoch_init=0):\n",
    "    n_epochs = int(config['epochs'])\n",
    "    iter_num = 0\n",
    "    best_dice = 0.0\n",
    "    for epoch in range(epoch_init, n_epochs):\n",
    "        scheduler.step()\n",
    "        train_loss = 0.0\n",
    "        val_scores_full = 0.0\n",
    "        val_scores_miss = 0.0\n",
    "        \n",
    "        for phase in ['train', 'eval']:\n",
    "            loader = loaders[phase]\n",
    "            total = len(loader)\n",
    "            for batch_id, (batch_x, batch_y) in enumerate(loader):\n",
    "                iter_num = iter_num + 1\n",
    "                batch_x, batch_y = batch_x.cuda(non_blocking=True), batch_y.cuda(non_blocking=True)\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    seg_f, style_f, content_f = model_full(batch_x[:,0:])\n",
    "                    seg_m, style_m, content_m = model_missing(batch_x[:,0:1])\n",
    "                    loss_dict = losses['co_loss'](config, seg_f, content_f, batch_y, seg_m, content_m, style_f, style_m, epoch)\n",
    "                   \n",
    "                    d_style.train()\n",
    "                    optimizer_d_style = optim.Adam(d_style.parameters(), lr = float(config['lr']), betas=(0.9, 0.99))\n",
    "                    # labels for style adversarial training\n",
    "                    source_label = 0\n",
    "                    target_label = 1\n",
    "\n",
    "                    optimizer.zero_grad()\n",
    "                    optimizer_d_style.zero_grad()\n",
    "                    \n",
    "                    # only train. Don't accumulate grads in disciminators\n",
    "                    for param in d_style.parameters():\n",
    "                        param.requires_grad = False\n",
    "\n",
    "                    if phase == 'train':\n",
    "                        (loss_dict['loss_Co']).backward(retain_graph=True)\n",
    "                        train_loss += loss_dict['loss_Co'].item()\n",
    "                    \n",
    "\n",
    "                    \n",
    "                    \n",
    "                    ##################### adversarial training ot fool the discriminator ######################\n",
    "                    df_src_main = style_f\n",
    "                    df_trg_main = style_m\n",
    "                    d_df_out_main = d_style(df_trg_main)\n",
    "                    loss_adv_df_trg_main = bce_loss(d_df_out_main, source_label)\n",
    "                    loss = 0.0002 * loss_adv_df_trg_main\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()                    \n",
    "                    \n",
    "                    \n",
    "                    ####################### Train discriminator networks ######################################\n",
    "                    # enable training mode on discriminator networks\n",
    "                    for param in d_style.parameters():\n",
    "                        param.requires_grad = True\n",
    "                    df_src_main = df_src_main.detach()\n",
    "                    d_df_out_main = d_style(df_src_main)\n",
    "                    loss_d_feature_main = bce_loss(d_df_out_main, source_label)\n",
    "                    if phase == 'train':\n",
    "                        loss_d_feature_main.backward()\n",
    "                    \n",
    "                    ####################### train with target ##################################################\n",
    "                    df_trg_main = df_trg_main.detach()\n",
    "                    d_df_out_main = d_style(df_trg_main)\n",
    "                    loss_d_feature_main = bce_loss(d_df_out_main, target_label)\n",
    "\n",
    "                    if phase == 'train':\n",
    "                        loss_d_feature_main.backward()\n",
    "\n",
    "                \n",
    "                num_classes = 4\n",
    "\n",
    "                if phase == 'train':\n",
    "                    optimizer.step()\n",
    "                    optimizer_d_style.step()\n",
    "                    if (batch_id + 1) % 20 == 0:\n",
    "                        print(f'Epoch {epoch+1}>> itteration {batch_id+1}>> training loss>> {train_loss/(batch_id+1)}')\n",
    " \n",
    "                else:\n",
    "                    val_scores_full += measure_dice_score(seg_f, batch_y)\n",
    "                    val_scores_miss += measure_dice_score(seg_m, batch_y)\n",
    "           \n",
    "            if phase == 'train':\n",
    "                print(f'Epoch {epoch+1} overall training loss>> {train_loss/(batch_id+1)}')\n",
    "            else:\n",
    "                dice = (val_scores_miss/(batch_id+1))\n",
    "                print(f'Epoch {epoch+1} validation dice score for missing modality>> {dice}')\n",
    "                state = {}\n",
    "                state['model_full'] = model_full.state_dict()\n",
    "                state['model_missing'] = model_missing.state_dict()\n",
    "                state['d_style'] = d_style.state_dict()\n",
    "                state['optimizer'] = optimizer.state_dict()\n",
    "                state['epochs'] = epoch\n",
    "                file_name = log_dir+'/model_weights.pth'\n",
    "                torch.save(state, file_name)\n",
    "                if dice > best_dice:\n",
    "                    torch.save(state, file_name)\n",
    "                    best_dice = dice\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "entertaining-justice",
   "metadata": {},
   "outputs": [],
   "source": [
    "saved_model_path = log_dir+'/model_weights.pth'\n",
    "if continue_training:\n",
    "    model_full, model_missing, d_style, optimizer, epoch = load_old_model(model_full, model_missing, d_style, optimizer, saved_model_path)\n",
    "\n",
    "train_val(model_full, model_missing, d_style, loaders, optimizer, scheduler, losses, epoch)\n",
    "print('Training process is finished')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "digital-pipeline",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_cuda11",
   "language": "python",
   "name": "pytorch_cuda11"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
